---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.3
  kernelspec:
    display_name: Python AIML
    language: python
    name: aiml
---

```{python}
import numpy as np
import torch
import torch_geometric.datasets as datasets
import torch_geometric.data as data
import torch_geometric.transforms as transforms
import networkx as nx
from torch_geometric.utils.convert import to_networkx

from torch_geometric.data import InMemoryDataset
from tqdm import tqdm
```

```{python}
import os
```

```{python}
import pandas as pd
from torch_geometric.data import Data
```

```{python}
df = pd.read_csv('AirPollutionSeoul/Measurement_summary.csv')
```

```{python}
df['Station code'].unique()
```

```{python}
df.head()
```

```{python}
df.drop_duplicates(subset=['Latitude', 'Longitude'])
```

```{python}
df1 = pd.read_csv('AirPollutionSeoul/Original Data/Measurement_info.csv')
```

```{python}
df1.head()
```

```{python}
df2 = pd.read_csv('AirPollutionSeoul/Original Data/Measurement_item_info.csv')
```

```{python}
df2.head()
```

```{python}
df.plot(x="Longitude", y="Latitude", kind="scatter", c="PM2.5", colormap="YlOrRd")
```

```{python}
df.info()
```

```{python}
station = pd.read_csv('AirPollutionSeoul/Original Data/Measurement_station_info.csv')
```

```{python}
station
```

```{python}
station.loc[:, 'Latitude']
```

```{python}
import matplotlib.pyplot as plt
```

```{python}
y = station.loc[:, 'Latitude']
z = station.loc[:, 'Longitude']
n = station.loc[:, 'Station code']

fig, ax = plt.subplots()
ax.scatter(z, y)

for i, txt in enumerate(n):
    ax.annotate(txt, (z[i], y[i]))
```

```{python}
station101 = df[df['Station code'] == 101]
```

```{python}
station101['Measurement date'] = pd.to_datetime(station101['Measurement date'], format='%Y-%m-%d %H:%M')
```

```{python}
station101.set_index(['Measurement date'], inplace=True)
```

```{python}
station101.iloc[0 : 24 * 365]['PM2.5'].plot()
```

```{python}
vars()['a'] = 1
```

```{python}
station = dict()
for i in [101, 116, 118, 125, 114]:
    station[f'{i}'] = df[df['Station code'] == i].iloc[0 : 24 * 365]
```

```{python}
station['101']
```

```{python}
data = station['101']
```

```{python}
data.iloc[0, 5:].tolist()
```

```{python}
data_list = []
```

```{python}
edge_index = torch.tensor([[1, 2, 3, 4, 0, 0, 0, 0],
                                         [0, 0, 0, 0, 1, 2, 3, 4]], dtype=torch.long)
for i in range(5):
    A = []
    L = []
    for code in [101, 116, 118, 125, 114]:
        data = station[f'{code}']
        A.append(data.iloc[i, 5:].tolist())
    L.append(station[f'101'].iloc[i+1,10].tolist())
#     print(A)
#     print(L)
#     print('-'*50)
    x = torch.tensor(A, dtype=torch.float)
    y = torch.tensor(L, dtype=torch.float)
    data = Data(x=x, y=y, edge_index=edge_index)
    data_list.append(data)
```

```{python}
data_list
```

```{python}
class AirPollutionData(InMemoryDataset):
    def __init__(self, root, transform=None, pre_transform=None):
        super(AirPollutionData, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_file_names(self):
        return []
    @property
    def processed_file_names(self):
        return ['AirPollution2.p']

    def download(self):
        pass
    
    def process(self):
        
        data_list = []

        # process by session_id
        
        edge_index = torch.tensor([[1, 2, 3, 4, 0, 0, 0, 0],
                                         [0, 0, 0, 0, 1, 2, 3, 4]], dtype=torch.long)
        for i in range(365*24 - 1):
            A = []
            L = []
            for code in [101, 116, 118, 125, 114]:
                data = station[f'{code}']
                A.append(data.iloc[i, 5:].tolist())
            L.append(station[f'101'].iloc[i+1,10].tolist())

            x = torch.tensor(A, dtype=torch.float)
            y = torch.tensor(L, dtype=torch.float)
            data = Data(x=x, y=y, edge_index=edge_index)
            
            data_list.append(data)
        
        data, slices = self.collate(data_list)
        torch.save((data, slices), self.processed_paths[0])
```

```{python}
dataset = AirPollutionData(root='../')
```

```{python}
dataset
```

```{python}
dataset = dataset.shuffle()
train_dataset = dataset[:6000]
val_dataset = dataset[6000:7500]
test_dataset = dataset[7500:]
len(train_dataset), len(val_dataset), len(test_dataset)
```

```{python}
from torch_geometric.data import DataLoader
batch_size= 256
train_loader = DataLoader(train_dataset, batch_size=batch_size)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
test_loader = DataLoader(test_dataset, batch_size=batch_size)
```

```{python}
data = dataset[0]
```

```{python}
data.num_nodes
```

```{python}
data.num_edges
```

```{python}
data.num_node_features
```

```{python}
data.is_undirected()
```

```{python}
dataset = dataset.shuffle()
```

```{python}
perm = torch.randperm(len(dataset))
dataset = dataset[perm]
```

```{python}
train_dataset = dataset[:540]
```

```{python}
test_dataset = dataset[540:700]
```

```{python}
data
```

```{python}

```
